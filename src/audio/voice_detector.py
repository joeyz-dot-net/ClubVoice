"""
è¯­éŸ³æ´»åŠ¨æ£€æµ‹å™¨ (VAD) - ç”¨äº Audio Ducking
æ£€æµ‹ Clubdeck æˆ¿é—´ä¸­æ˜¯å¦æœ‰äººè¯´è¯
"""
import numpy as np
from typing import Optional
from dataclasses import dataclass


@dataclass
class VoiceDetectionConfig:
    """è¯­éŸ³æ£€æµ‹é…ç½®"""
    threshold: float = 150.0          # RMS é˜ˆå€¼ï¼ˆint16 èŒƒå›´ï¼š0-32768ï¼‰
    min_duration: float = 0.1         # æœ€å°æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰- é¿å…è¯¯è§¦å‘
    release_time: float = 0.5         # é‡Šæ”¾æ—¶é—´ï¼ˆç§’ï¼‰- è¯­éŸ³åœæ­¢åå¤šä¹…æ¢å¤éŸ³é‡
    smooth_frames: int = 3            # å¹³æ»‘å¸§æ•° - é¿å…é¢‘ç¹åˆ‡æ¢


class VoiceActivityDetector:
    """
    è¯­éŸ³æ´»åŠ¨æ£€æµ‹å™¨
    ç”¨äºæ£€æµ‹ VB-Cable Aï¼ˆClubdeck æˆ¿é—´ï¼‰ä¸­çš„è¯­éŸ³æ´»åŠ¨
    """
    
    def __init__(self, sample_rate: int = 48000, config: Optional[VoiceDetectionConfig] = None):
        """
        Args:
            sample_rate: é‡‡æ ·ç‡
            config: æ£€æµ‹é…ç½®
        """
        self.sample_rate = sample_rate
        self.config = config or VoiceDetectionConfig()
        
        # çŠ¶æ€è·Ÿè¸ª
        self.is_voice_active = False
        self.active_frames = 0      # è¿ç»­æ´»è·ƒå¸§æ•°
        self.silent_frames = 0      # è¿ç»­é™éŸ³å¸§æ•°
        
        # è®¡ç®—å¸§æ•°é˜ˆå€¼ï¼ˆå‡è®¾æ¯å¸§ 512 samplesï¼‰
        samples_per_frame = 512
        self.min_active_frames = max(1, int(
            self.config.min_duration * sample_rate / samples_per_frame
        ))
        self.release_frames = max(1, int(
            self.config.release_time * sample_rate / samples_per_frame
        ))
        
        print(f"[VAD] åˆå§‹åŒ– - é˜ˆå€¼: {self.config.threshold}, "
              f"æœ€å°æŒç»­: {self.config.min_duration}s, "
              f"é‡Šæ”¾æ—¶é—´: {self.config.release_time}s")
    
    def detect(self, audio_data: np.ndarray) -> bool:
        """
        æ£€æµ‹éŸ³é¢‘å¸§ä¸­æ˜¯å¦æœ‰è¯­éŸ³æ´»åŠ¨
        
        Args:
            audio_data: int16 æ ¼å¼çš„éŸ³é¢‘æ•°æ®ï¼ˆå¯ä»¥æ˜¯ç«‹ä½“å£°æˆ–å•å£°é“ï¼‰
            
        Returns:
            True å¦‚æœæ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨
        """
        # è®¡ç®— RMSï¼ˆå‡æ–¹æ ¹ï¼‰éŸ³é‡
        rms = np.sqrt(np.mean(audio_data.astype(np.float32) ** 2))
        
        # åˆ¤æ–­æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        if rms > self.config.threshold:
            self.active_frames += 1
            self.silent_frames = 0
            
            # è¾¾åˆ°æœ€å°æŒç»­å¸§æ•°æ‰è®¤ä¸ºæ˜¯æœ‰æ•ˆè¯­éŸ³
            if self.active_frames >= self.min_active_frames:
                if not self.is_voice_active:
                    self.is_voice_active = True
                    print(f"[VAD] ğŸ”Š æ£€æµ‹åˆ°è¯­éŸ³ (RMS: {rms:.1f})")
        else:
            self.active_frames = 0
            self.silent_frames += 1
            
            # é™éŸ³æ—¶é—´è¶…è¿‡é‡Šæ”¾æ—¶é—´æ‰å…³é—­æ£€æµ‹
            if self.silent_frames >= self.release_frames:
                if self.is_voice_active:
                    self.is_voice_active = False
                    print(f"[VAD] ğŸ”‡ è¯­éŸ³åœæ­¢")
        
        return self.is_voice_active
    
    def get_status(self) -> dict:
        """è·å–æ£€æµ‹å™¨çŠ¶æ€ä¿¡æ¯"""
        return {
            'active': self.is_voice_active,
            'active_frames': self.active_frames,
            'silent_frames': self.silent_frames,
            'threshold': self.config.threshold
        }
    
    def reset(self):
        """é‡ç½®æ£€æµ‹å™¨çŠ¶æ€"""
        self.is_voice_active = False
        self.active_frames = 0
        self.silent_frames = 0
        print("[VAD] æ£€æµ‹å™¨å·²é‡ç½®")
